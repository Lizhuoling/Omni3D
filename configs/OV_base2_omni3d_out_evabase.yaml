_BASE_: "Base_Omni3D.yaml"

DATASETS:
  #TRAIN: ('nuScenes_train', 'nuScenes_val', 'KITTI_train', 'KITTI_val')
  TRAIN: ('KITTI_val',)
  #TEST: ('nuScenes_test', 'KITTI_test') 
  TEST: ('KITTI_val',)
  CATEGORY_NAMES: ('cyclist', 'pedestrian', 'trailer', 'bus', 'motorcycle', 'car', 'barrier', 'truck', 'van', 'traffic cone', 'bicycle')

INPUT:
  MIN_SIZE_TRAIN: (512,)
  MIN_SIZE_TEST: 512
  RANDOM_FLIP: "none"
  COLOR_AUG: True

SOLVER:
  IMS_PER_BATCH: 2
  #IMS_PER_BATCH: 64
  TYPE: "adamw"
  BASE_LR: 4e-4
  MAX_ITER: 116000

  LR_SCHEDULER_NAME: "WarmupCosineLR"
  WARMUP_FACTOR: 0.3333
  WARMUP_ITERS: 500
  WARMUP_METHOD: "linear"

  CLIP_GRADIENTS: 
    ENABLED: True
    CLIP_VALUE: 35.0
    NORM_TYPE: 2.0

TEST:
  EVAL_PERIOD: 11600

MODEL:
  META_ARCHITECTURE: "OV_3D_Det"

  DETECTOR3D:
    DETECT_ARCHITECTURE: "petr"

    PETR:
      GRID_MASK: True

      BACKBONE_NAME: 'EVA_Base'
      BACKBONE_FP16: True
      NECK_NAME: 'CPFPN_VoV'
      TRANSFORMER_NAME: 'PETR_TRANSFORMER'
      MATCHER_NAME: 'HungarianAssigner3D'
      DEPTH_LID: True
      NUM_QUERY: 200

      HEAD:
        OV_CLS_HEAD: True
        PERFORM_2D_DET: False
        UNCERN_RANGE: [-10, 10]
        CLS_WEIGHT: 2.0
        REG_WEIGHT: 0.25
        DET_2D_L1_WEIGHT: 5.0
        DET_2D_GIOU_WEIGHT: 2.0

      POST_PROCESS:
        CONFIDENCE_2D_THRE: 0.0
        CONFIDENCE_3D_THRE: -1.0
        OUTPUT_CONFIDENCE: '3D'

  GLIP_MODEL:
    USE_GLIP: True
    GLIP_INITIALIZE_QUERY: True
    NO_GRADIENT: True
    GLIP_WEIGHT: "MODEL/glip_a_tiny_o365.pth"

    MODEL:
      META_ARCHITECTURE: "GeneralizedVLRCNN"
      WEIGHT: "swin_tiny_patch4_window7_224.pth"
      RPN_ONLY: True
      RPN_ARCHITECTURE: "VLDYHEAD"

      BACKBONE:
        CONV_BODY: "SWINT-FPN-RETINANET"
        OUT_CHANNELS: 256
        FREEZE_CONV_BODY_AT: -1

      LANGUAGE_BACKBONE:
        FREEZE: False
        MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
        MASK_SPECIAL: False

      RPN:
        USE_FPN: True
        ANCHOR_SIZES: (64, 128, 256, 512, 1024)
        ANCHOR_STRIDE: (8, 16, 32, 64, 128)
        ASPECT_RATIOS: (1.0,)
        SCALES_PER_OCTAVE: 1

      DYHEAD:
        CHANNELS: 256
        NUM_CONVS: 6
        USE_GN: True
        USE_DYRELU: True
        USE_DFCONV: True
        USE_DYFUSE: True
        TOPK: 9 # topk for selecting candidate positive samples from each level
        SCORE_AGG: "MEAN"
        LOG_SCALE: 0.0

        FUSE_CONFIG:
          EARLY_FUSE_ON: False
          TYPE: "MHA-B"
          USE_CLASSIFICATION_LOSS: False
          USE_TOKEN_LOSS: False
          USE_CONTRASTIVE_ALIGN_LOSS: False
          CONTRASTIVE_HIDDEN_DIM: 64
          USE_DOT_PRODUCT_TOKEN_LOSS: True
          USE_FUSED_FEATURES_DOT_PRODUCT: False
          USE_LAYER_SCALE: True
          CLAMP_MIN_FOR_UNDERFLOW: True
          CLAMP_MAX_FOR_OVERFLOW: True
          CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
          CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
          CLAMP_DOT_PRODUCT: True
              
        USE_CHECKPOINT: True

      ATSS:
        DETECTIONS_PER_IMG: 100 # Maximum proposal number produced by GLIP

    TEST:
      DURING_TRAINING: False
      IMS_PER_BATCH: 64

    # use for grounding model
    DATASETS:
      TRAIN: ("object365_dt_train", )
      TEST: ("coco_2017_val", )
      DISABLE_SHUFFLE: False
      ADD_DET_PROMPT: False
      RANDOM_SAMPLE_NEG: 85
      CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

      SEPARATION_TOKENS: ". "

    INPUT:
      PIXEL_MEAN: [123.675, 116.280, 103.530] # vovnet
      PIXEL_STD: [58.395, 57.120, 57.375] # vovnet
      MIN_SIZE_TRAIN: 800
      MAX_SIZE_TRAIN: 1333
      MIN_SIZE_TEST: 800
      MAX_SIZE_TEST: 1333

    AUGMENT:
      MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

    DATALOADER:
      SIZE_DIVISIBILITY: 32

    SOLVER:
      OPTIMIZER: ADAMW
      BASE_LR: 0.0001
      LANG_LR: 0.00001
      WEIGHT_DECAY: 0.0001
      STEPS: (0.67, 0.89)
      MAX_EPOCH: 30
      IMS_PER_BATCH: 64
      WARMUP_ITERS: 2000
      WARMUP_FACTOR: 0.001
      USE_AMP: True
      MODEL_EMA: 0.999
      FIND_UNUSED_PARAMETERS: False

      CLIP_GRADIENTS:
        ENABLED: True
        CLIP_TYPE: "full_model"
        CLIP_VALUE: 1.0
        NORM_TYPE: 2.0