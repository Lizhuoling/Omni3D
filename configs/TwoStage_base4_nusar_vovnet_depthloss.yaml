_BASE_: "Base_Omni3D_demo.yaml"

DATASETS:
  TRAIN: ('nuScenes_train', 'nuScenes_val', 'ARKitScenes_train', 'ARKitScenes_val')
  #TRAIN: ('ARKitScenes_val',)
  TEST: ('nuScenes_test', 'ARKitScenes_test',) 
  #TEST: ('ARKitScenes_val',)
  CATEGORY_NAMES: ('machine', 'shelves', 'chair', 'car', 'table', 'sofa', 'bus', 'cabinet', 'toilet', 'motorcycle', 'bathtub', 'oven', 'sink', 'traffic cone', 'truck', 'television', 'refrigerator', 'pedestrian', 'stove', 'bicycle', 'trailer', 'barrier', 'bed')
  DATASET_ID_GROUP: [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14], [15, 16, 17],]

INPUT:
  RESIZE_TGT_SIZE: (640, 512)
  RANDOM_FLIP: "none"
  COLOR_AUG: True

SOLVER:
  IMS_PER_BATCH: 64
  TYPE: "mmcv_AdamW"
  BASE_LR: 4e-4
  WEIGHT_DECAY: 1e-2
  MAX_ITER: 29000
  VIRTUAL_EPOCHS: 20
  VIRTUAL_LOSS: 2.0   # To avoid the total loss is too small.

  LR_SCHEDULER_NAME: "CosineAnnealing"
  WARMUP_FACTOR: 0.3333
  WARMUP_ITERS: 7250
  WARMUP_METHOD: "linear"

  CLIP_GRADIENTS: 
    ENABLED: True
    CLIP_VALUE: 35.0
    NORM_TYPE: 2.0

TEST:
  EVAL_PERIOD: 14500

MODEL:
  META_ARCHITECTURE: "OV_3D_Det"

  DETECTOR3D:
    DETECT_ARCHITECTURE: "petr"
    OV_PROTOCOL: False

    PETR:
      GRID_MASK: False

      BACKBONE_NAME: 'VoVNet'
      BACKBONE_FP16: True
      NECK_NAME: 'SECONDFPN'
      TRANSFORMER_NAME: 'DEFORMABLE_TRANSFORMER'
      ITER_QUERY_UPDATE: False
      TRANSFORMER_DROPOUT: 0.1
      MATCHER_NAME: 'HungarianAssigner3D'
      NUM_QUERY: 200
      FEAT_LEVEL_IDXS: ('stage2', 'stage3', 'stage4', 'stage5')
      DOWNSAMPLE_FACTOR: 16
      LID: True
      LID_DEPTH: False
      LLS_SPARSE: 1e-3
      FEAT3D_FORM: "bev"  # "bev" or "voxel"
      DEPTH_SUPERVISION: True
      ADAPT_LN: False

      CENTER_PROPOSAL:
        USE_CENTER_PROPOSAL: True
        TRAIN_GT_CENTER: False
        FOCAL_DECOUPLE: True
        VIRTUAL_FOCAL_Y: 512.0
        PROPOSAL_NUMBER: 100
        OBJ_LOSS_WEIGHT: 1.0
        DEPTH_LOSS_WEIGHT: 0.2
        OFFSET_LOSS_WEIGHT: 1.0
        PROPOSAL_CONF_THRE: 0.2

      HEAD:
        OV_CLS_HEAD: False
        UNCERN_RANGE: [-10, 10]
        CLS_WEIGHT: 2.0
        LOC_WEIGHT: 0.25
        DIM_WEIGHT: 0.25
        POSE_WEIGHT: 0.25
        DEPTH_HEAD_WEIGHT: 1.0
        DET_2D_L1_WEIGHT: 5.0
        DET_2D_GIOU_WEIGHT: 2.0

        ENC_NUM: 1
        DEC_NUM: 6

        POSITION_RANGE: [-30, 30, -40, 40, 0, 80]
        GRID_SIZE: [1, 80, 1]
        D_BOUND: [0.1, 100, 1]
        ENC_CAM_INTRINSIC: True 
        CLS_MASK: True 

      POST_PROCESS:
        CONFIDENCE_2D_THRE: 0.0
        CONFIDENCE_3D_THRE: -1.0
        OUTPUT_CONFIDENCE: '3D'

  GLIP_MODEL:
    USE_GLIP: False
    GLIP_INITIALIZE_QUERY: False
    NO_GRADIENT: True
    GLIP_WEIGHT: "MODEL/glip_a_tiny_o365.pth"

    MODEL:
      META_ARCHITECTURE: "GeneralizedVLRCNN"
      WEIGHT: "swin_tiny_patch4_window7_224.pth"
      RPN_ONLY: True
      RPN_ARCHITECTURE: "VLDYHEAD"

      BACKBONE:
        CONV_BODY: "SWINT-FPN-RETINANET"
        OUT_CHANNELS: 256
        FREEZE_CONV_BODY_AT: -1

      LANGUAGE_BACKBONE:
        FREEZE: False
        MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
        MASK_SPECIAL: False

      RPN:
        USE_FPN: True
        ANCHOR_SIZES: (64, 128, 256, 512, 1024)
        ANCHOR_STRIDE: (8, 16, 32, 64, 128)
        ASPECT_RATIOS: (1.0,)
        SCALES_PER_OCTAVE: 1

      DYHEAD:
        CHANNELS: 256
        NUM_CONVS: 6
        USE_GN: True
        USE_DYRELU: True
        USE_DFCONV: True
        USE_DYFUSE: True
        TOPK: 9 # topk for selecting candidate positive samples from each level
        SCORE_AGG: "MEAN"
        LOG_SCALE: 0.0

        FUSE_CONFIG:
          EARLY_FUSE_ON: False
          TYPE: "MHA-B"
          USE_CLASSIFICATION_LOSS: False
          USE_TOKEN_LOSS: False
          USE_CONTRASTIVE_ALIGN_LOSS: False
          CONTRASTIVE_HIDDEN_DIM: 64
          USE_DOT_PRODUCT_TOKEN_LOSS: True
          USE_FUSED_FEATURES_DOT_PRODUCT: False
          USE_LAYER_SCALE: True
          CLAMP_MIN_FOR_UNDERFLOW: True
          CLAMP_MAX_FOR_OVERFLOW: True
          CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
          CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
          CLAMP_DOT_PRODUCT: True
              
        USE_CHECKPOINT: True

      ATSS:
        DETECTIONS_PER_IMG: 100 # Maximum proposal number produced by GLIP

    TEST:
      DURING_TRAINING: False
      IMS_PER_BATCH: 64

    # use for grounding model
    DATASETS:
      TRAIN: ("object365_dt_train", )
      TEST: ("coco_2017_val", )
      DISABLE_SHUFFLE: False
      ADD_DET_PROMPT: False
      RANDOM_SAMPLE_NEG: 85
      CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

      SEPARATION_TOKENS: ". "

    INPUT:
      PIXEL_MEAN: [123.675, 116.280, 103.530] # vovnet
      PIXEL_STD: [58.395, 57.120, 57.375] # vovnet
      MIN_SIZE_TRAIN: 800
      MAX_SIZE_TRAIN: 1333
      MIN_SIZE_TEST: 800
      MAX_SIZE_TEST: 1333

    AUGMENT:
      MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

    DATALOADER:
      SIZE_DIVISIBILITY: 32

    SOLVER:
      OPTIMIZER: ADAMW
      BASE_LR: 0.0001
      LANG_LR: 0.00001
      WEIGHT_DECAY: 0.0001
      STEPS: (0.67, 0.89)
      MAX_EPOCH: 30
      IMS_PER_BATCH: 64
      WARMUP_ITERS: 2000
      WARMUP_FACTOR: 0.001
      USE_AMP: True
      MODEL_EMA: 0.999
      FIND_UNUSED_PARAMETERS: False

      CLIP_GRADIENTS:
        ENABLED: True
        CLIP_TYPE: "full_model"
        CLIP_VALUE: 1.0
        NORM_TYPE: 2.0
